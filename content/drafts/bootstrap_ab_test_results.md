Title: Three ways to analyze your A/B test results incorrectly
Author: Spencer Nelson
Date: 2013-09-03 5:31:00
Slug: primer-on-ab-test-analysis
Status: draft

In the startup world, A/B tests are widely used, but I get the sense that not many people think too hard about how to analyze the data they find. This can be dangerous; without a healthy respect for uncertainty, it's easy to crown meaningless random walk as a legitimate improvement which wastes development resources and can mislead you into an incorrect understanding of your users.

You don't see too many people completely *ignoring* statistics these days, but in general people just trust whatever they get out of an off-the-shelf tool like Optimizely. 